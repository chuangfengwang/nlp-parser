## 原始描述

具体需求： -分词、词性标注、词频统计（主要是提取动词周围的名词进行统计）； -短语结构分析，统计CFG规则频次 文件大小txt100k左右，不用重新训练模型啥的，用现成的即可

## 需求拆解

分词,词性标注,依存句法 词频统计 CFG规则

## 输出格式

句子表: 文件,句子,首字母偏移量,解析器 词语表: 句子id,词语,词性,上位词 分叉表: 关系,左词语,右词语,左词id,右词id,关系代号,左词性,右词性

## 运行分析

# 开发时的路径
java -jar target/nlp-parser-1.0-SNAPSHOT-jar-with-dependencies.jar -r data/filterRegex.txt -c conll_output.txt -d nlpparsed.sqlite3 data/lz-data/shentiyundongxunlian.txt data/lz-data/tushouxunlian.txt data/lz-data/yujia.txt

# linux / mac
java -jar nlp-parser-1.0-SNAPSHOT-jar-with-dependencies.jar -r filterRegex.txt -c conll_output.txt -d nlpparsed.sqlite3 data/lz-data/shentiyundongxunlian.txt data/lz-data/tushouxunlian.txt data/lz-data/yujia.txt

# windows
# 如果解压路径是 D:\\xxx\\yyy
# 先切换到解压的目录:
D:
cd xxx\\yyy
# 进行依存句法分析,并把结果存到数据库 nlpparsed.sqlite3
java -jar nlp-parser-1.0-SNAPSHOT-jar-with-dependencies.jar -r filterRegex.txt -c conll_output.txt -d nlpparsed.sqlite3 data\\lz-data\\shentiyundongxunlian.txt data\\lz-data\\tushouxunlian.txt data\\lz-data\\yujia.txt

java -jar nlp-parser-1.0-SNAPSHOT-jar-with-dependencies.jar -r filterRegex.txt -c conll_output.txt -d nlpparsed.sqlite3 D:\\！！！！！！！！毕业论文\\nlp-parser.tar\\nlp-parser\\nlp-parser-jar\\data\\lz-data\\shentiyundongxunlian.txt D:\\！！！！！！！！毕业论文\\nlp-parser.tar\\nlp-parser\\nlp-parser-jar\\data\\lz-data\\tushouxunlian.txt D:\\！！！！！！！！毕业论文\\nlp-parser.tar\\nlp-parser\\nlp-parser-jar\\data\\lz-data\\yujia.txt

## 统计脚本

词频统计

```sql
.mode tabs

.output word_frequency.txt
-- 动词搭配的词频
select w1.deprel
     , w1.cpostag
     , w2.cpostag
     , w1.word
     , w2.word
     , s.file_name
--      , s.sent
--      , s.file_name
     , count(1) num
from parsed_word w1
         join parsed_word w2 on w1.sent_id = w2.sent_id and w1.head_no = w2.word_no
         join parsed_sent s on w1.sent_id = s.id
where (w1.cpostag = 'n' and w2.cpostag = 'v')
   or (w1.cpostag = 'v' and w2.cpostag = 'n')
group by w1.deprel, w1.cpostag, w2.cpostag, w1.word, w2.word, s.file_name
order by num desc
;

.output cfg_frequency.txt
-- CFG规则频次
select c.deprel
     , c.left_cpostag
     , c.right_cpostag
     , s.file_name
--      , c.left_word
--      , c.right_word
--      , s.sent
     , count(1) as num
from parsed_cfg_pair c
         join parsed_sent s on c.sent_id = s.id
where c.deprel in ('主谓关系', '动宾关系', '间宾关系', '前置宾语', '动补结构', '兼语', '介宾关系')
group by c.deprel, c.left_cpostag, c.right_cpostag, s.file_name
order by num desc
;

.output stdout
.mode list
```
